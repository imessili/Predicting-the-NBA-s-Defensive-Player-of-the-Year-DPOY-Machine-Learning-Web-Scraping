{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1c89d1-3254-4d54-93d7-279a54a2cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.20745356114708538\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California housing dataset\n",
    "california_housing = fetch_california_housing()\n",
    "\n",
    "# Create a DataFrame\n",
    "X = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
    "y = california_housing.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize XGBoost regressor with parallelization\n",
    "xgb_reg = XGBRegressor(learning_rate=0.1, n_estimators=500, max_depth=5, objective='reg:squarederror', n_jobs=-1)\n",
    "\n",
    "# Train the model\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b469acb8-b032-41b2-a353-2f978e14ee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.49716071275105733\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California housing dataset\n",
    "california_housing = fetch_california_housing()\n",
    "\n",
    "# Create a DataFrame\n",
    "X = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
    "y = california_housing.target\n",
    "\n",
    "# Selecting specific columns\n",
    "selected_features = ['Longitude', 'MedInc']\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize XGBoost regressor with parallelization\n",
    "xgb_reg = XGBRegressor(learning_rate=0.1, n_estimators=500, max_depth=5, objective='reg:squarederror', n_jobs=-1)\n",
    "\n",
    "# Train the model\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "619f2cbd-6117-4485-9cbc-d430c1cefdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features based on Pearson correlation coefficient:\n",
      "MedInc: 0.6880752079585469\n",
      "AveRooms: 0.1519482897414577\n",
      "Latitude: 0.1441602768746582\n",
      "HouseAge: 0.10562341249320949\n",
      "AveBedrms: 0.04670051296948675\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Calculate Pearson correlation coefficients between features and target variable\n",
    "correlations = {}\n",
    "for feature in X.columns:\n",
    "    correlation, _ = pearsonr(X[feature], y)\n",
    "    correlations[feature] = abs(correlation)\n",
    "\n",
    "# Sort the features by their correlation with the target variable\n",
    "sorted_correlations = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top features based on correlation coefficient\n",
    "top_features = [feature for feature, correlation in sorted_correlations[:5]]  # Selecting top 5 features\n",
    "\n",
    "print(\"Top features based on Pearson correlation coefficient:\")\n",
    "for feature, correlation in sorted_correlations[:5]:\n",
    "    print(f\"{feature}: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cea8b523-62cc-45df-9cda-7317a273593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features based on Mutual Information scores:\n",
      "Longitude: 0.3995484574076329\n",
      "MedInc: 0.3875033850264291\n",
      "Latitude: 0.3684838710710805\n",
      "AveRooms: 0.10333844972600925\n",
      "AveOccup: 0.07217356375695427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Calculate mutual information between features and target variable\n",
    "mi_scores = mutual_info_regression(X, y)\n",
    "\n",
    "# Create a dictionary to store mutual information scores for each feature\n",
    "mi_scores_dict = {}\n",
    "for i, feature in enumerate(X.columns):\n",
    "    mi_scores_dict[feature] = mi_scores[i]\n",
    "\n",
    "# Sort the features by their mutual information scores\n",
    "sorted_mi_scores = sorted(mi_scores_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top features based on mutual information\n",
    "top_features = [feature for feature, mi_score in sorted_mi_scores[:5]]  # Selecting top 5 features\n",
    "\n",
    "print(\"Top features based on Mutual Information scores:\")\n",
    "for feature, mi_score in sorted_mi_scores[:5]:\n",
    "    print(f\"{feature}: {mi_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c8d94-129a-4952-a3fb-8e8ebda87e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes, mutual information (MI) and Pearson correlation coefficient can give different rankings for feature importance, and this is because they capture different aspects of the relationship between features and the target variable.\n",
    "\n",
    "Mutual Information (MI):\n",
    "\n",
    "Mutual information measures the amount of information obtained about one variable through the other variable. In the context of feature selection, it quantifies the amount of information that a feature provides about the target variable.\n",
    "MI can capture both linear and non-linear relationships between variables.\n",
    "It does not make any assumptions about the distribution of the data, making it suitable for a wide range of data types.\n",
    "Pearson Correlation Coefficient:\n",
    "\n",
    "Pearson correlation coefficient measures the linear correlation between two variables. It ranges from -1 to 1, where:\n",
    "1 indicates a perfect positive linear relationship,\n",
    "-1 indicates a perfect negative linear relationship, and\n",
    "0 indicates no linear relationship.\n",
    "It only captures linear relationships between variables. Non-linear relationships might not be captured accurately.\n",
    "It assumes that the variables are normally distributed.\n",
    "In the case of the California housing dataset:\n",
    "\n",
    "MI might capture non-linear relationships between features and the target variable, which Pearson correlation may miss.\n",
    "Pearson correlation might overemphasize features with linear relationships with the target variable and might not capture important non-linear relationships.\n",
    "Therefore, the rankings obtained from MI and Pearson correlation can differ, as they each emphasize different aspects of the relationship between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fca74-4552-49ec-8a90-499a12b096c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RidgeCV is a linear regression model and, by definition, can capture linear relationships between variables \n",
    "and the target. However, it may not capture non-linear relationships between variables and\n",
    "the target directly. Ridge regression penalizes the size of the coefficients to prevent overfitting,\n",
    "but it doesn't introduce non-linear transformations of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28085941-e762-43c4-93e5-beb1f941d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "To analyze the consistency of feature rankings obtained from Mutual Information (MI) across different subsets of your data (in this case, different years), you can use Kendall's Tau correlation coefficient. Kendall's Tau measures the similarity of rankings between two different ranking methods. Here's how you can approach it:\n",
    "\n",
    "Compute the Kendall's Tau correlation coefficient between the rankings obtained from MI for each pair of years.\n",
    "Average the Kendall's Tau coefficients to obtain an overall measure of consistency across the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47465d65-399d-47d0-a641-a801a320a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "When computing Kendall's Tau correlation coefficient to compare rankings obtained from Mutual Information (MI) scores across different subsets of your data, you should pass the rankings themselves rather than the scores.\n",
    "\n",
    "Here's why:\n",
    "\n",
    "Kendall's Tau compares rankings: Kendall's Tau is designed to compare rankings between two lists of items. It measures the similarity in the order of items between the two lists, regardless of the magnitude of the values.\n",
    "\n",
    "Rankings preserve the relative importance: When you pass rankings instead of scores, you're focusing on the relative importance of features within each subset of data. This is what matters when assessing the consistency of feature importance across different subsets.\n",
    "\n",
    "Therefore, you should pass the rankings of features based on their MI scores to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
